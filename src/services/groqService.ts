import { DistrictData } from "../types";

// Groq API Configuration
// Groq API Configuration
// Call backend proxy instead of direct Groq API
const GROQ_API_URL = import.meta.env.VITE_API_BASE_URL ? `${import.meta.env.VITE_API_BASE_URL}/chat.php` : "http://localhost/airhanoi/api/chat.php";
const GROQ_MODEL = "llama-3.3-70b-versatile"; // Fast and powerful


interface GroqMessage {
    role: "system" | "user" | "assistant";
    content: string;
}

// Call Groq API with streaming for real-time response
const callGroqChat = async (
    systemPrompt: string,
    userPrompt: string,
    onChunk?: (text: string) => void
): Promise<string> => {
    const messages: GroqMessage[] = [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
    ];

    const response = await fetch(GROQ_API_URL, {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
        },
        body: JSON.stringify({
            model: GROQ_MODEL,
            messages,
            stream: true,
            temperature: 0.7,
            max_tokens: 1024,
        }),
    });

    if (!response.ok) {
        const errorText = await response.text();
        console.error("Groq API error:", response.status, errorText);
        throw new Error(`Groq API lá»—i (${response.status}): ${errorText}`);
    }

    const reader = response.body?.getReader();
    if (!reader) {
        throw new Error("KhÃ´ng thá»ƒ Ä‘á»c streaming response tá»« Groq.");
    }

    const decoder = new TextDecoder();
    let fullContent = "";

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n').filter(line => line.trim() && line.startsWith('data: '));

        for (const line of lines) {
            const data = line.replace('data: ', '').trim();
            if (data === '[DONE]') continue;

            try {
                const json = JSON.parse(data);
                const content = json?.choices?.[0]?.delta?.content || "";
                if (content) {
                    fullContent += content;
                    if (onChunk) {
                        onChunk(fullContent);
                    }
                }
            } catch {
                // Skip invalid JSON
            }
        }
    }

    if (!fullContent) {
        throw new Error("Groq tráº£ vá» pháº£n há»“i rá»—ng.");
    }
    return fullContent;
};

interface AIResponse {
    text: string;
    sources?: { title: string; url: string }[];
}

export const generateAIResponse = async (
    question: string,
    contextData: DistrictData[],
    onChunk?: (text: string) => void
): Promise<AIResponse> => {
    console.log("ğŸš€ generateAIResponse (Groq) called with question:", question);

    // Prepare system data summary
    const avgAQI = contextData.length > 0
        ? Math.round(contextData.reduce((acc, d) => acc + d.aqi, 0) / contextData.length)
        : 0;

    const topPolluted = [...contextData].sort((a, b) => b.aqi - a.aqi).slice(0, 5);
    const topClean = [...contextData].sort((a, b) => a.aqi - b.aqi).slice(0, 5);

    const dataSummary = `
ğŸ“Š THá»NG KÃŠ Tá»”NG QUAN (${contextData.length} khu vá»±c):
- AQI trung bÃ¬nh: ${avgAQI}
- Má»©c Ä‘á»™: ${avgAQI <= 50 ? 'Tá»‘t' : avgAQI <= 100 ? 'Trung bÃ¬nh' : avgAQI <= 150 ? 'KÃ©m' : avgAQI <= 200 ? 'Xáº¥u' : 'Ráº¥t xáº¥u'}

ğŸ”´ TOP 5 Ã” NHIá»„M NHáº¤T:
${topPolluted.map((d, i) => `${i + 1}. ${d.district}: AQI ${d.aqi} (${d.pollution_level}), PM2.5: ${d.pm25}Âµg/mÂ³`).join('\n')}

ğŸŸ¢ TOP 5 Sáº CH NHáº¤T:
${topClean.map((d, i) => `${i + 1}. ${d.district}: AQI ${d.aqi} (${d.pollution_level}), PM2.5: ${d.pm25}Âµg/mÂ³`).join('\n')}

ğŸ“‹ CHI TIáº¾T Táº¤T Cáº¢ KHU Vá»°C:
${contextData.map(d => `${d.district}: AQI ${d.aqi}, PM2.5: ${d.pm25}, Nhiá»‡t Ä‘á»™: ${d.temperature}Â°C, Äá»™ áº©m: ${d.humidity}%`).join('\n')}
`;

    const systemPrompt = `Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn gia vá» cháº¥t lÆ°á»£ng khÃ´ng khÃ­ táº¡i HÃ  Ná»™i tÃªn lÃ  "AirHanoi AI".

ğŸ¯ NHIá»†M Vá»¤:
- PhÃ¢n tÃ­ch vÃ  tráº£ lá»i cÃ¢u há»i dá»±a trÃªn Dá»® LIá»†U THá»œI GIAN THá»°C bÃªn dÆ°á»›i
- ÄÆ°a ra lá»i khuyÃªn sá»©c khá»e cá»¥ thá»ƒ, há»¯u Ã­ch
- Tráº£ lá»i báº±ng ngÃ´n ngá»¯ ngÆ°á»i dÃ¹ng sá»­ dá»¥ng (Tiáº¿ng Viá»‡t hoáº·c Tiáº¿ng Anh)

ğŸ“ QUY Táº®C:
- Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch (tá»‘i Ä‘a 200 tá»«)
- Sá»­ dá»¥ng emoji phÃ¹ há»£p Ä‘á»ƒ dá»… Ä‘á»c
- Æ¯u tiÃªn dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p, khÃ´ng bá»‹a sá»‘ liá»‡u
- Náº¿u Ä‘Æ°á»£c há»i vá» khu vá»±c cá»¥ thá»ƒ, tÃ¬m trong dá»¯ liá»‡u vÃ  tráº£ lá»i chÃ­nh xÃ¡c
- ÄÆ°a ra cáº£nh bÃ¡o sá»©c khá»e khi AQI > 100

${dataSummary}`;

    const userPrompt = question;

    try {
        const text = await callGroqChat(systemPrompt, userPrompt, onChunk);
        return { text, sources: [] };
    } catch (error: any) {
        console.error("Groq Chat Error:", error);
        return {
            text: `âŒ ÄÃ£ xáº£y ra lá»—i khi káº¿t ná»‘i vá»›i AI: ${error?.message || 'Unknown error'}. Vui lÃ²ng thá»­ láº¡i.`
        };
    }
};

export const generateRouteAdvice = async (
    startDistrict: DistrictData,
    endDistrict: DistrictData,
    onChunk?: (text: string) => void
): Promise<string> => {
    const systemPrompt = `Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n sá»©c khá»e vÃ  di chuyá»ƒn trong Ä‘iá»u kiá»‡n Ã´ nhiá»…m khÃ´ng khÃ­ táº¡i HÃ  Ná»™i.

ğŸ¯ NHIá»†M Vá»¤: ÄÆ°a ra lá»i khuyÃªn di chuyá»ƒn an toÃ n dá»±a trÃªn chá»‰ sá»‘ AQI cá»§a Ä‘iá»ƒm Ä‘i vÃ  Ä‘iá»ƒm Ä‘áº¿n.

ğŸ“ QUY Táº®C:
- Tráº£ lá»i ngáº¯n gá»n (dÆ°á»›i 100 tá»«)
- Äá» xuáº¥t phÆ°Æ¡ng tiá»‡n phÃ¹ há»£p (xe mÃ¡y/Ã´ tÃ´/taxi/bus)
- Khuyáº¿n nghá»‹ loáº¡i kháº©u trang cáº§n thiáº¿t
- Cáº£nh bÃ¡o sá»©c khá»e náº¿u AQI cao
- Sá»­ dá»¥ng emoji cho dá»… Ä‘á»c`;

    const userPrompt = `ğŸš— Lá»˜ TRÃŒNH DI CHUYá»‚N:
- Äiá»ƒm Ä‘i: ${startDistrict.district} (AQI: ${startDistrict.aqi}, PM2.5: ${startDistrict.pm25}Âµg/mÂ³, ${startDistrict.pollution_level})
- Äiá»ƒm Ä‘áº¿n: ${endDistrict.district} (AQI: ${endDistrict.aqi}, PM2.5: ${endDistrict.pm25}Âµg/mÂ³, ${endDistrict.pollution_level})

HÃ£y Ä‘Æ°a ra lá»i khuyÃªn di chuyá»ƒn an toÃ n.`;

    try {
        return await callGroqChat(systemPrompt, userPrompt, onChunk);
    } catch (error: any) {
        console.error("Route advice error:", error);
        return "âŒ KhÃ´ng thá»ƒ láº¥y lá»i khuyÃªn tá»« AI lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i.";
    }
};

// Quick analysis function for dashboard widgets
export const quickAnalysis = async (
    contextData: DistrictData[],
    analysisType: 'summary' | 'health' | 'forecast'
): Promise<string> => {
    const avgAQI = contextData.length > 0
        ? Math.round(contextData.reduce((acc, d) => acc + d.aqi, 0) / contextData.length)
        : 0;

    const prompts = {
        summary: `AQI trung bÃ¬nh HÃ  Ná»™i: ${avgAQI}. TÃ³m táº¯t tÃ¬nh hÃ¬nh trong 2 cÃ¢u.`,
        health: `AQI trung bÃ¬nh: ${avgAQI}. ÄÆ°a ra 3 lá»i khuyÃªn sá»©c khá»e ngáº¯n gá»n.`,
        forecast: `AQI hiá»‡n táº¡i: ${avgAQI}. Dá»± Ä‘oÃ¡n xu hÆ°á»›ng trong ngÃ y.`
    };

    const systemPrompt = "Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch khÃ´ng khÃ­. Tráº£ lá»i cá»±c ká»³ ngáº¯n gá»n (tá»‘i Ä‘a 50 tá»«), sá»­ dá»¥ng emoji.";

    try {
        return await callGroqChat(systemPrompt, prompts[analysisType]);
    } catch {
        return "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch lÃºc nÃ y.";
    }
};
